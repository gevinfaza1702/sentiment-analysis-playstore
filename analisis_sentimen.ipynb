{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e5bc03-02e3-4f75-bf39-73b7b47fb6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing selesai! 2356 ulasan telah dibersihkan.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load dataset hasil scraping\n",
    "df = pd.read_csv('ulasan_google_play.csv')\n",
    "\n",
    "# Hapus duplikasi\n",
    "df.drop_duplicates(subset='content', inplace=True)\n",
    "\n",
    "# Hapus ulasan kosong\n",
    "df = df[df['content'].str.strip().astype(bool)]\n",
    "\n",
    "# Membersihkan teks ulasan\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Hanya menyisakan huruf dan spasi\n",
    "    text = text.lower().strip()  # Mengubah teks menjadi huruf kecil\n",
    "    return text\n",
    "\n",
    "df['cleaned_content'] = df['content'].apply(clean_text)\n",
    "\n",
    "# Simpan hasil preprocessing\n",
    "df.to_csv('cleaned_ulasan_google_play.csv', index=False)\n",
    "print(f\"Preprocessing selesai! {len(df)} ulasan telah dibersihkan.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44e6a80-e935-47cb-b6e0-8ff384757aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pelabelan selesai! Data siap untuk analisis sentimen.\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset yang sudah dibersihkan\n",
    "df = pd.read_csv('cleaned_ulasan_google_play.csv')\n",
    "\n",
    "# Pastikan tidak ada nilai NaN\n",
    "df = df.dropna(subset=['cleaned_content'])\n",
    "\n",
    "# Konversi ke string untuk mencegah error\n",
    "df['cleaned_content'] = df['cleaned_content'].astype(str)\n",
    "\n",
    "# Inisialisasi Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analisis Sentimen\n",
    "df['sentiment_score'] = df['cleaned_content'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Konversi skor ke kategori sentimen\n",
    "def label_sentiment(score):\n",
    "    if score >= 0.05:\n",
    "        return \"positif\"\n",
    "    elif score <= -0.05:\n",
    "        return \"negatif\"\n",
    "    else:\n",
    "        return \"netral\"\n",
    "\n",
    "df['sentiment'] = df['sentiment_score'].apply(label_sentiment)\n",
    "\n",
    "# Simpan hasil pelabelan\n",
    "df.to_csv('labeled_ulasan_google_play.csv', index=False)\n",
    "print(\"Pelabelan selesai! Data siap untuk analisis sentimen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eae7487-cece-4744-9928-57f37b73cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ekstraksi fitur dengan TF-IDF selesai!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load dataset yang sudah memiliki label sentimen\n",
    "df = pd.read_csv('labeled_ulasan_google_play.csv')\n",
    "\n",
    "# Ekstraksi fitur menggunakan TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(df['cleaned_content'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Simpan model TF-IDF agar bisa digunakan nanti\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "print(\"Ekstraksi fitur dengan TF-IDF selesai!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681528e0-9aa6-46ef-9b97-d88675062f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model SVM telah dilatih dan disimpan!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Membagi data menjadi train dan test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Melatih model SVM\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Simpan model\n",
    "with open(\"model_svm.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "\n",
    "print(\"Model SVM telah dilatih dan disimpan!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718f9caa-ff21-43cc-84c2-c6774e6249a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model SVM: 93.60%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       1.00      0.56      0.72        32\n",
      "      netral       0.93      1.00      0.96       399\n",
      "     positif       1.00      0.58      0.73        38\n",
      "\n",
      "    accuracy                           0.94       469\n",
      "   macro avg       0.98      0.71      0.81       469\n",
      "weighted avg       0.94      0.94      0.93       469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Load model dan data\n",
    "with open(\"model_svm.pkl\", \"rb\") as f:\n",
    "    svm_model = pickle.load(f)\n",
    "\n",
    "# Prediksi\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Akurasi Model SVM: {accuracy_svm:.2%}\")\n",
    "print(report_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719dd917-0bd4-4267-aa5c-e68921e6d007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "# Load dataset dan model\n",
    "with open(\"model_svm.pkl\", \"rb\") as f:\n",
    "    svm_model = pickle.load(f)\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10]}\n",
    "grid = GridSearchCV(LinearSVC(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5cd198-ea72-4f5e-b67b-5aaf993fba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Sentimen: netral\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load model TF-IDF dan model SVM\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "with open(\"model_svm.pkl\", \"rb\") as f:\n",
    "    svm_model = pickle.load(f)\n",
    "\n",
    "# Contoh ulasan baru\n",
    "new_review = [\"Aplikasi ini sangat lambat dan sering crash.\"]\n",
    "new_review_tfidf = tfidf.transform(new_review)\n",
    "\n",
    "# Prediksi sentimen\n",
    "predicted_sentiment = svm_model.predict(new_review_tfidf)\n",
    "\n",
    "print(f\"Prediksi Sentimen: {predicted_sentiment[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a5b9e-a9b3-4d9a-a708-4547bbb6037f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
